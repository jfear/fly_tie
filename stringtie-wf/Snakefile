import sys
sys.path.insert(0, srcdir('../lcdb-wf'))
import os
from textwrap import dedent
import yaml
import tempfile
import pandas as pd
from lcdblib.snakemake import helpers, aligners
from lcdblib.utils import utils
from lib import common
from lib import cluster_specific
from lib.patterns_targets import RNASeqConfig


configfile: 'config/config.yaml'

include: '../references-wf/Snakefile'
shell.prefix('set -euo pipefail; export TMPDIR={};'.format(cluster_specific.tempdir_for_biowulf()))
shell.executable('/bin/bash')

config = common.load_config(config)

c = RNASeqConfig(config, config.get('patterns', 'config/rnaseq_patterns.yaml'))

wildcard_constraints:
    n = '[1,2]'


def wrapper_for(path):
    return 'file:' + os.path.join('../lcdb-wf','wrappers', 'wrappers', path)

# ----------------------------------------------------------------------------
# RULES
# ----------------------------------------------------------------------------
# TODO add code to make stringtie params.

final_targets = utils.flatten((
    c.targets['bam'],
))

# Special case: all samples are single-end
if all(c.sampletable.iloc[:, 0].apply(
    lambda x: not common.is_paired_end(c.sampletable, x))
):
    ALL_SE = True
    final_targets = [i.replace('{n}', '1') for i in final_targets]
else:
    ALL_SE = False

rule targets:
    """
    Final targets to create
    """
    input: final_targets

def render_r1_r2(pattern):
    if ALL_SE:
        return expand(pattern, sample='{sample}', n=[1])
    return expand(pattern, sample='{sample}', n=[1, 2])

# Convert the sampletable to be indexed by the first column, for
# convenience in generating the input/output filenames.
_st = c.sampletable.set_index(c.sampletable.columns[0])

rule fastq_dump:
    output:
        fastq=render_r1_r2(c.patterns['fastq'])
    run:
        srr = _st.loc[wildcards.sample, 'Run']

        # Two different paths depending on the layout. In both cases, we
        # want to avoid creating the final output until the very end, to
        # avoid incomplete downloads.
        if common.is_paired_end(c.sampletable, wildcards.sample):

            # For PE we need to use --split-files, which also means using
            # the slower --gzip
            shell(
                'fastq-dump '
                '{srr} '
                '--gzip '
                '--split-files '
                # '-X 100000 ' # [TEST SETTINGS]
            )

            # The filenames are predictable, so we can move them as needd.
            shell('mv {srr}_1.fastq.gz {output[0]}')
            shell('mv {srr}_2.fastq.gz {output[1]}')

        else:
            # For SE, we can use the faster stdout | gzip, and move it
            # directly when done.
            shell(
                'fastq-dump '
                '{srr} '
                '-Z '
                # '-X 100000 ' # [TEST SETTINGS]
                '| gzip -c > {output[0]}.tmp '
                '&& mv {output[0]}.tmp {output[0]} '
            )
            if not ALL_SE:
                shell('touch {output[1]}')


rule cutadapt:
    """
    Run cutadapt
    """
    input:
        fastq=common.fill_r1_r2(c.sampletable, c.patterns['fastq'])
    output:
        fastq=render_r1_r2(c.patterns['cutadapt'])
    log:
        render_r1_r2(c.patterns['cutadapt'])[0] + '.log'
    run:
        paired = len(input) == 2

        # NOTE: Change cutadapt params here
        extra='-a file:../lcdb-wf/include/adapters.fa -q 20 --minimum-length=25'

        if paired:
            shell(
                "cutadapt "
                "{extra} "
                "{input.fastq[0]} "
                "{input.fastq[1]} "
                "-o {output[0]} "
                "-p {output[1]} "
                "&> {log}"
            )
        else:
            shell(
                "cutadapt "
                "{extra} "
                "{input.fastq[0]} "
                "-o {output[0]} "
                "&> {log}"
            )
            if not ALL_SE:
                shell('touch {output[1]}')


rule hisat2:
    """
    Map reads with HISAT2
    """
    input:
        fastq=common.fill_r1_r2(c.sampletable, c.patterns['cutadapt']),
        index=[c.refdict[c.organism][config['aligner']['tag']]['hisat2']]
    output:
        bam=c.patterns['bam']
    log:
        c.patterns['bam'] + '.log'
    params:
        # NOTE: see examples at
        # https://github.com/lcdb/lcdb-wf/tree/master/wrappers/wrappers/hisat2/align
        # for details on setting hisat2 params and samtools params separately.
        samtools_view_extra='-F 0x04'
    threads: 6
    script:
        wrapper_for('hisat2/align/wrapper.py')


rule bam_count:
    """
    Count reads in a BAM file
    """
    input:
        bam='{sample_dir}/{sample}/{suffix}.bam'
    output:
        count='{sample_dir}/{sample}/{suffix}.bam.libsize'
    shell:
        'samtools view -c {input} > {output}'


rule bam_index:
    """
    Index a BAM
    """
    input:
        bam='{prefix}.bam'
    output:
        bai='{prefix}.bam.bai'
    shell:
        'samtools index {input} {output}'


#TODO add StringTie

# TODO add GFFcompare or someother metric


# vim: ft=python
